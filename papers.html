<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <title>Shuai Zheng</title>
    <meta name="author" content="Shuai Zheng">

    <!-- Le styles -->
    <link href="css/bootstrap.min.css" rel="stylesheet">
    <link rel="stylesheet" href="css/font-awesome.min.css">
    <link href="css/style.css?body=1" rel="stylesheet" type="text/css" media="all">

    <style type="text/css">
      body {
        padding-top: 30px;
        padding-bottom: 30px;
      }

      h3 {
        margin-top: 0.7em;
        margin-bottom: 0.3em;
        padding-bottom: 0.2em;
        line-height: 1.0;
        border-bottom: 1px solid #aaaaaa;
      }

      li {
        font-size: 15px;
        margin: 20px 0;
      }

      p {
         line-height: 25px;
      }

    </style>


  </head>

  <body>

<div class="navbar navbar-inverse navbar-fixed-top">
      <div class="navbar-inner">
        <div class="container">
          <a class="brand" href="./index.html">Shuai Zheng</a>
          <a class="brand" href="./index.html">Home</a>
          <a class="brand" href="./papers.html"> Papers </a>
          <a class="brand" href="./service.html"> Services </a>
          <ul class="nav">
          </ul>
        </div>
        </div>
      </div>
    </div>

<div id="wrap">

<div class="container">

  <div class="content">


    <h2> Papers </h2>
<ul>
  <li>
    <p>
      <a href=""> Lancet: Accelerating Mixture-of-Experts Training by Overlapping Weight Gradient Computation and All-to-All Communication </a> </br>
      Chenyu Jiang, Ye Tian, Zhen Jia, Chuan Wu, Yida Wang, <b>Shuai Zheng</b> </br>
      <i> The 7th Annual Conference on Machine Learning and Systems (MLSys), Santa Clara, CA, USA, May 2024 </i> </br>
    </p>
  </li>
  <li>
    <p>
      <a href=""> DISTMM: Accelerating Distributed Multi-modal Model Training </a> </br>
      Jun Huang, Zhen Zhang, Feng Qin, Yida Wang, <b>Shuai Zheng</b> </br>
      <i> The 21st USENIX Symposium on Networked Systems Design and Implementation (NSDI), Santa Clara, CA, USA, April 2024 </i> </br>
    </p>
  </li>
    <li>
    <p>
      <a href="https://arxiv.org/pdf/2305.04241.pdf"> VCC: Scaling Transformers to 128K Tokens or More by Prioritizing Important Tokens </a> </br>
      Zhanpeng Zeng, Cole Hawkins, Mingyi Hong, Aston Zhang, Nikolaos Pappas, Vikas Singh, <b>Shuai Zheng</b> </br>
      <i> The 37th Conference on Neural Information Processing Systems (NeurIPS), New Orleans, USA, Dec 2023 </i> </br>
    </p>
  </li>
    <li>
    <p>
      <a href="https://arxiv.org/pdf/2304.04704.pdf"> Prompt Pre-Training with Twenty-Thousand Classes for Open-Vocabulary Visual Recognition </a> </br>
      Shuhuai Ren, Aston Zhang, Yi Zhu, Shuai Zhang, <b>Shuai Zheng</b>, Mu Li, Alex Smola, Xu Sun </br>
      <i> The 37th Conference on Neural Information Processing Systems (NeurIPS), New Orleans, USA, Dec 2023 </i> </br>
    </p>
  </li>
    <li>
    <p>
      <a href="https://arxiv.org/pdf/2311.10418.pdf"> DynaPipe: Optimizing Multi-task Training through Dynamic Pipelines </a> </br>
      Chenyu Jiang, Zhen Jia, <b>Shuai Zheng</b>, Yida Wang, Chuan Wu </br>
      <i> The 19th European Conference on Computer Systems (EuroSys), Athens, Greece, April 2024 </i> </br>
    </p>
  </li>
    <li>
    <p>
      <a href="https://assets.amazon.science/29/31/6523473f48e4af52252bac56ef51/gemini-fast-failure-recovery-in-distributed-training-with-in-memory-checkpoints.pdf"> GEMINI: Fast Failure Recovery in Distributed Training with In-Memory Checkpoints </a> </br>
      Zhuang Wang, Zhen Jia, <b>Shuai Zheng</b>, Zhen Zhang, Xinwei Fu, T. S. Eugene Ng, Yida Wang </br>
      <i> The 29th ACM Symposium on Operating Systems Principles (SOSP), Koblenz, Germany, October 2023 </i> </br>
    </p>
  </li>
   <li>
    <p>
      <a href="https://arxiv.org/pdf/2302.08005.pdf"> Slapo: A Schedule Language for Efficient Progressive Optimization of Large Deep Learning Model Training </a> </br>
      Hongzheng Chen, Cody Hao Yu, <b>Shuai Zheng</b>, Zhen Zhang, Zhiru Zhang, Yida Wang </br>
      <i> The ACM International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS), San Diego, CA, USA, April 2024 </i> </br>
    </p>
  </li>
  <li>
    <p>
      <a href="https://arxiv.org/pdf/2205.00119.pdf"> MiCS: Near-linear Scaling for Training Gigantic Model on Public Cloud </a> [<a href="https://www.amazon.science/blog/near-linear-scaling-of-gigantic-model-training-on-aws">Amazon blog</a>] [<a href="https://docs.aws.amazon.com/sagemaker/latest/dg/model-parallel-extended-features-pytorch-sharded-data-parallelism.html">SageMaker</a>] </br>
      Zhen Zhang, <b>Shuai Zheng</b>, Yida Wang, Justin Chiu, George Karypis, Trishul Chilimbi, Mu Li, Xin Jin </br>
      <i> The 49th International Conference on Very Large Data Bases (VLDB), Vancouver, Canada, August 2023 </i> </br>
    </p>
  </li>
  <li>
    <p>
      <a href="https://arxiv.org/pdf/2212.10929.pdf"> SPT: Semi-Parametric Prompt Tuning for Multitask Prompted Learning </a> </br>
      M Saiful Bari, Aston Zhang, <b>Shuai Zheng</b>, Xingjian Shi, Yi Zhu, Shafiq Joty, Mu Li </br>
      <i> arXiv:2212.10929, Dec 2022 </i> </br>
    </p>
  </li>
  <li>
    <p>
      <a href="https://arxiv.org/pdf/2212.05191.pdf"> SMILE: Scaling Mixture-of-Experts with Efficient Bi-level Routing </a> </br>
      Chaoyang He, <b>Shuai Zheng</b>, Aston Zhang, George Karypis, Trishul Chilimbi, Mahdi Soltanolkotabi, Salman Avestimehr </br>
      <i> arXiv:2212.05191, Dec 2022 </i> </br>
    </p>
  </li>
  <li>
    <p>
      <a href="https://proceedings.mlr.press/v162/wang22aq/wang22aq.pdf"> Partial and Asymmetric Contrastive Learning for Out-of-Distribution Detection in Long-Tailed Recognition </a> </br>
      Haotao Wang, Aston Zhang, Yi Zhu, <b>Shuai Zheng</b>, Mu Li, Alex Smola, Zhangyang Wang </br>
      <i> The 39th International Conference on Machine Learning (ICML, Long Oral), Baltimore, Maryland, USA, July 2022 </i> </br>
    </p>
  </li>
  <li>
    <p>
      <a href="https://proceedings.mlr.press/v162/wang22ap/wang22ap.pdf"> Removing Batch Normalization Boosts Adversarial Training </a> </br>
      Haotao Wang, Aston Zhang, <b>Shuai Zheng</b>, Xingjian Shi, Mu Li, Zhangyang Wang </br>
      <i> The 39th International Conference on Machine Learning (ICML), Baltimore, Maryland, USA, July 2022 </i> </br>
    </p>
  </li>
  <li>
    <p>
      <a href="https://arxiv.org/pdf/2206.07808.pdf"> Alexa Teacher Model: Pretraining and Distilling Multi-Billion-Parameter Encoders for Natural Language Understanding Systems </a> </br>
      Jack FitzGerald, Shankar Ananthakrishnan, Konstantine Arkoudas, Davide Bernardi, Abhishek Bhagia, Claudio Delli Bovi, Jin Cao, Rakesh Chada, Amit Chauhan,
Luoxin Chen, Anurag Dwarakanath, Satyam Dwivedi,
Turan Gojayev, Karthik Gopalakrishnan, Thomas Gueudre,
Dilek Hakkani-Tur, Wael Hamza, Jonathan Hueser,
Kevin Martin, Jose Haidar Khan, Beiye Liu,
Jianhua Lu, Alessandro Manzotti, Pradeep Natarajan,
Karolina Owczarzak, Gokmen Oz, Enrico Palumbo,
Charith Peris, Chandana Satya Prakash, Stephen Rawls,
Andy Rosenbaum, Anjali Shenoy, Saleh Soltan,
Mukund Harakere Sridhar, Liz Tan, Fabian Triefenbach,
Pan Wei, Haiyang Yu, <b>Shuai Zheng</b>,
Gokhan Tur, Prem Natarajan  </br>
      <i> The 28th ACM SIGKDD Conference (KDD), Washington DC, August, 2022 </i> </br>
    </p>
  </li>
  <li>
    <p>
      <a href="https://www2022.thewebconf.org/PaperFiles/22.pdf"> DCAF-BERT: A Distilled Cachable Adaptable Factorized Model For Improved Ads CTR Prediction </a> </br>
      Aashiq Muhamed, Jaspreet Singh, <b>Shuai Zheng</b>, Iman Keivanloo, Sujan Perera, Jame Mracek, Yi Xu, Qingjun Cui, Sunny Rajagopalan, Belinda Zeng, Trishul Chilimbi </br>
      <i> The 31st ACM Web Conference (WWW), Lyon, France, April 2022 </i> </br>
    </p>
  </li>
    <li>
    <p>
    <a href="https://openreview.net/pdf?id=HMR-7-4-Zr"> Contractive Error Feedback for Gradient Compression </a> </br>
    Bingcong Li, <b>Shuai Zheng</b>, Parameswaran Raman, Anshumali Shrivastava, Georgios B. Giannakis </br>
    <i> Preprint 2021 </i> </br>
    </p>
  </li>
  <li>
  <p>
     <a href='https://assets.amazon.science/c6/0e/2dd56cfb4c839ecb8a676447d52b/context-language-modeling-and-multimodal-data-in-finance.pdf'> Context, Language Modeling, and Multimodal Data in Finance </a> </br>
  Sanjiv Das, Connor Goggins, John He, George Karypis, Sandeep Krishnamurthy, Mitali Mahajan, Nagpurnanand Prabhala, Shenghua Yue, Dylan Slack, Rob van Dusen, Sheng Zha, <b> Shuai Zheng</b> </br>
  <i> Authors listed in alphabetic order </i> </br>
  <i> The Journal of Financial Data Science, Summer 2021 </i> </br>
  </p>
  </li>
    <li>
   <p>
    <a href="https://arxiv.org/pdf/2105.07829.pdf"> Compressed Communication for Distributed Training: Adaptive Methods and System </a> [<a href="https://github.com/vycezhong/byteps-compress">code</a>] </br>
    Yuchen Zhong, Cong Xie, <b> Shuai Zheng</b>, Haibin Lin </br>
    <i> Preprint arXiv:2105.07829, May 2021 </i> </br>
  </p>
  </li>
  <li>
  <p>
     <a href="https://proceedings.neurips.cc/paper/2020/file/94cb02feb750f20bad8a85dfe7e18d11-Paper.pdf"> CSER: Communication-efficient SGD with Error Reset </a> </br>
  Cong Xie, <b> Shuai Zheng</b>, Oluwasanmi Koyejo, Indranil Gupta, Mu Li, Haibin Lin </br>
  <i> The 34th Conference on Neural Information Processing Systems (NeurIPS), Vancouver, Canada, Dec 2020 </i> </br>
  </p>
  </li>
  <li>
  <p>
     <a href="https://arxiv.org/abs/2006.13484"> Accelerated Large Batch Optimization of BERT Pretraining in 54 minutes </a> </br>
  <b> Shuai Zheng</b>, Haibin Lin, Sheng Zha, Mu Li </br>
  <i> Preprint arXiv:2006.13484, June 2020 </i> </br>
  </p>
  </li>
   <li>
   <p>
     <a href="papers/jmlr2020.pdf"> GluonCV and GluonNLP: Deep Learning in Computer Vision and Natural Language Processing </a> </br>
      Jian Guo, He He, Tong He, Leonard Lausen, Mu Li, Haibin Lin, Xingjian Shi, Chenguang Wang, Junyuan Xie, Sheng Zha, Aston Zhang, Hang Zhang, Zhi Zhang, Zhongyue Zhang, <b>Shuai Zheng</b>, Yi Zhu </br>
     <i> Authors listed in alphabetic order </i> </br>
     <i> Journal of Machine Learning Research (JMLR), Feb 2020 </i> </br>
   </p>
   </li>
   <li>
    <p>
        <a href="papers/nips19.pdf"> Communication-Efficient Distributed Blockwise Momentum SGD with Error-Feedback </a> [<a href="https://github.com/ZiyueHuang/dist-ef-sgdm">code</a>]</br>
       <b>Shuai Zheng</b>, Ziyue Huang, James T. Kwok</br>
       <i>The 33rd Conference on Neural Information Processing Systems (NeurIPS), Vancouver, Canada, Dec 2019 </i> </br>
    </p>
  </li>
  <li>
  <p>
     <a href="http://arxiv.org/abs/1905.09899"> Blockwise Adaptivity: Faster Training and Better Generalization in Deep
  Learning </a> </br>
  <b> Shuai Zheng</b>, James T. Kwok </br>
  <i> Preprint arXiv:1905.09899, May 2019 </i> </br>
  </p>
  </li>
  <li>
    <p>
        <a href="papers/icml18.pdf"> Lightweight Stochastic Optimization for Minimizing Finite Sums with Infinite Data </a> </br>
       <b>Shuai Zheng</b>, James T. Kwok</br>
       <i>The 35th International Conference on Machine Learning (ICML), Stockholm, Sweden, July 2018 </i> </br>
    </p>
  </li>
  <li>
    <p>
       <a href="papers/icml17.pdf"> Follow the Moving Leader in Deep Learning </a>  [<a href="papers/icml17_supplementary.pdf">supplementary</a>]  </br>
       <b>Shuai Zheng</b>, James T. Kwok</br>
       <i>The 34th International Conference on Machine Learning (ICML), Sydney, Australia, August 2017 </i> </br>
    </p>
  </li>
  <li>
    <p>
       <a href="papers/ijcai16.pdf"> Fast-and-Light Stochastic ADMM </a> [<a href="papers/ijcai16_supplementary.pdf">supplementary</a>]  [<a href="https://arxiv.org/abs/1604.07070">longer arxiv version</a>] </br>
       <b>Shuai Zheng</b>, James T. Kwok</br>
       <i>The 25th International Joint Conference on Artificial Intelligence (IJCAI), New York, New York, USA, July 2016 </i> </br>
    </p>
  </li>
  <li>
    <p>
       <a href="papers/aaai16a.pdf"> Fast Nonsmooth Regularized Risk Minimization with Continuation </a>[<a href="papers/aaai16a_supplementary.pdf">supplementary</a>] </br>
       <b>Shuai Zheng</b>, Ruiliang Zhang, James T. Kwok</br>
       <i>The 30th AAAI Conference on Artificial Intelligence (AAAI), Phoenix, Arizona, USA, Feb 2016 </i> </br>
    </p>
  </li>
  <li>
    <p>
       <a href="papers/aaai16b.pdf"> Asynchronous Distributed Semi-Stochastic Gradient Optimization </a>[<a href="papers/aaai16b_supplementary.pdf">supplementary</a>]</br>
       Ruiliang Zhang, <b>Shuai Zheng</b>, James T. Kwok</br>
       <i>The 30th AAAI Conference on Artificial Intelligence (AAAI), Phoenix, Arizona, USA, Feb 2016 </i> </br>
    </p>
  </li>
  <li>
    <p>
       <a href="papers/aaai14.pdf"> Accurate Integration of Aerosol Predictions by Smoothing on a Manifold </a>[<a href="code/aaai14_code.zip">code</a>][<a href="data/aaai14_data.zip">data</a>]</br>
       <b>Shuai Zheng</b>, James T. Kwok</br>
       <i> The 28th AAAI Conference on Artificial Intelligence (AAAI), Quebec City, Canada, July 2014 </i> </br>
    </p>
  </li>
  <li>
    <p>
       Flexible Navigation in Smartphones and Tablets using Scalable Storyboards</br>
       <b>Shuai Zheng</b>, Luis Herranz, Shuqiang Jiang </br>
       <i> The 3rd ACM International Conference on Multimedia Retrieval (ICMR), Dallas, Texas, USA, April 2013</i> </br>
    </p>
  </li>
</ul>
</div>
    </div>
    </div>

    <!-- Le javascript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="js/jquery.js"></script>
    <script src="js/bootstrap-transition.js"></script>
    <script src="js/bootstrap-alert.js"></script>
    <script src="js/bootstrap-modal.js"></script>
    <script src="js/bootstrap-dropdown.js"></script>
    <script src="js/bootstrap-scrollspy.js"></script>
    <script src="js/bootstrap-tab.js"></script>
    <script src="js/bootstrap-tooltip.js"></script>
    <script src="js/bootstrap-popover.js"></script>
    <script src="js/bootstrap-button.js"></script>
    <script src="js/bootstrap-collapse.js"></script>
    <script src="js/bootstrap-carousel.js"></script>
    <script src="js/bootstrap-typeahead.js"></script>

    </body>
</html>
